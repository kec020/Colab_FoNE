2025-08-21 22:58:15 - INFO - result/pretrained/Qwen/Qwen2.5-7B-Instruct/gsm8k/fne/period_base_list_[10.0]_batchsize_32_epochs_5_lr_5e-05_int_digit_len_5_frac_digit_len_5_seed42_num_train_samples_None_model_size_level_-1_lengensize_0_addlinear_True
2025-08-21 22:58:15 - INFO - Namespace(batch_size=32, epochs=5, int_digit_len=5, frac_digit_len=5, len_gen_size=0, lr=5e-05, name='', model='Qwen/Qwen2.5-7B-Instruct', dataset='openai/gsm8k', train_from_scratch=False, use_digit_wise_tokenizer=False, num_train_samples=None, num_test_samples=None, seed=42, model_size_level=-1, method='fne', scheduler_name='cosine', period_base_list=[10.0], clip=False, not_add_linear=False, use_lora=True, add_linear=True)
2025-08-21 22:58:15 - INFO - Dataset specified as single name: openai/gsm8k
2025-08-21 22:58:15 - INFO - Loading model with QLoRA configuration for fine-tuning
2025-08-21 22:58:16 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-08-21 22:58:28 - INFO - Applied LoRA configuration to the model.
2025-08-21 22:58:28 - INFO - Standard tokenizer loaded.
2025-08-21 22:58:28 - INFO - Expanded tokenizer by 397 dummy tokens to match model vocab_size=152064.
2025-08-21 22:58:28 - INFO - Actual model size (total parameters): 10.09M
2025-08-21 22:58:28 - INFO - Padding token ID: 151665
2025-08-21 22:58:28 - INFO - [NUM] token ID: 151666
2025-08-21 22:58:29 - INFO - Train dataset length: 7473, Test dataset length: 1319
2025-08-21 22:58:32 - INFO - 2 data example: [{'input_ids': tensor([    45,   4212,    685,   6088,  26111,    311,    256, 151666,    220,
           315,   1059,   4780,    304,   5813,     11,    323,   1221,   1340,
          6088,   4279,    438,   1657,  26111,    304,   3217,     13,   2585,
          1657,  26111,   1521,  41601,    685,   4559,  30055,    304,   5813,
           323,   3217,     30]), 'numbers': [48.0], 'label': 72.0}, {'input_ids': tensor([    54,    826,  63759,    400,    220, 151666,    220,    458,   6460,
           369,  70583,  14810,     13,  60033,     11,   1340,   1101,   1521,
           256, 151666,    220,   4420,    315,  70583,  14810,     13,   2585,
          1753,   1521,   1340,   7232,     30]), 'numbers': [12.0, 50.0], 'label': 10.0}]
2025-08-21 22:58:32 - INFO - period_list: [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0, 100000.0]
2025-08-21 22:58:32 - INFO - self.powers_of_ten: tensor([         1,         10,        100,       1000,      10000,     100000,
           1000000,   10000000,  100000000, 1000000000], device='cuda:0')
2025-08-21 22:58:32 - INFO - ----------------------------------------------------------------------------------------------------
2025-08-21 22:58:32 - INFO - Starting Epoch 1/5
2025-08-21 23:14:43 - INFO - avg Loss: 1.3907491381351764
2025-08-21 23:14:43 - INFO - Evaluation start
2025-08-21 23:15:43 - INFO - Mispredictions (up to 5 examples):
2025-08-21 23:15:43 - INFO - Predicted: 24.0, Actual: 18.0
2025-08-21 23:15:43 - INFO - Predicted: 31.0, Actual: 3.0
2025-08-21 23:15:43 - INFO - Predicted: 20.0, Actual: 70000.0
2025-08-21 23:15:43 - INFO - Predicted: 30.0, Actual: 540.0
2025-08-21 23:15:43 - INFO - Predicted: 23.0, Actual: 20.0
2025-08-21 23:15:43 - INFO - Epoch                                   1         
2025-08-21 23:15:43 - INFO - Train Loss                              1.3907
2025-08-21 23:15:43 - INFO - Test Loss                               0.8131
2025-08-21 23:15:43 - INFO - Whole Num Acc                           1.137225%
2025-08-21 23:15:43 - INFO - Digit-wise Acc                          31.486726%
2025-08-21 23:15:43 - INFO - MSE                                     8475044016.888859
2025-08-21 23:15:43 - INFO - R^2                                     -0.005600840202014
2025-08-21 23:15:43 - INFO - Learning Rate                           0.000050
2025-08-21 23:15:43 - INFO - ----------------------------------------------------------------------------------------------------
2025-08-21 23:15:43 - INFO - Starting Epoch 2/5
2025-08-21 23:32:00 - INFO - avg Loss: 0.7449557778672276
2025-08-21 23:32:00 - INFO - Evaluation start
2025-08-21 23:33:00 - INFO - Mispredictions (up to 5 examples):
2025-08-21 23:33:00 - INFO - Predicted: 17.0, Actual: 18.0
2025-08-21 23:33:00 - INFO - Predicted: 16.0, Actual: 3.0
2025-08-21 23:33:00 - INFO - Predicted: 14100.0, Actual: 70000.0
2025-08-21 23:33:00 - INFO - Predicted: 1200.0, Actual: 540.0
2025-08-21 23:33:00 - INFO - Predicted: 14.0, Actual: 20.0
2025-08-21 23:33:00 - INFO - Epoch                                   2         
2025-08-21 23:33:00 - INFO - Train Loss                              0.7450
2025-08-21 23:33:00 - INFO - Test Loss                               0.6962
2025-08-21 23:33:00 - INFO - Whole Num Acc                           2.653525%
2025-08-21 23:33:00 - INFO - Digit-wise Acc                          38.318584%
2025-08-21 23:33:00 - INFO - MSE                                     8382831988.087187
2025-08-21 23:33:00 - INFO - R^2                                     0.005340518150215
2025-08-21 23:33:00 - INFO - Learning Rate                           0.000043
2025-08-21 23:33:00 - INFO - ----------------------------------------------------------------------------------------------------
2025-08-21 23:33:00 - INFO - Starting Epoch 3/5
2025-08-21 23:49:12 - INFO - avg Loss: 0.6520000846467466
2025-08-21 23:49:12 - INFO - Evaluation start
2025-08-21 23:50:12 - INFO - Mispredictions (up to 5 examples):
2025-08-21 23:50:12 - INFO - Predicted: 19.0, Actual: 18.0
2025-08-21 23:50:12 - INFO - Predicted: 17.0, Actual: 3.0
2025-08-21 23:50:12 - INFO - Predicted: 20000.0, Actual: 70000.0
2025-08-21 23:50:12 - INFO - Predicted: 1790.0, Actual: 540.0
2025-08-21 23:50:12 - INFO - Predicted: 5.0, Actual: 20.0
2025-08-21 23:50:12 - INFO - Epoch                                   3         
2025-08-21 23:50:12 - INFO - Train Loss                              0.6520
2025-08-21 23:50:12 - INFO - Test Loss                               0.6484
2025-08-21 23:50:12 - INFO - Whole Num Acc                           2.350265%
2025-08-21 23:50:12 - INFO - Digit-wise Acc                          36.637168%
2025-08-21 23:50:12 - INFO - MSE                                     8300879617.225928
2025-08-21 23:50:12 - INFO - R^2                                     0.015064523456902
2025-08-21 23:50:12 - INFO - Learning Rate                           0.000025
2025-08-21 23:50:12 - INFO - ----------------------------------------------------------------------------------------------------
2025-08-21 23:50:12 - INFO - Starting Epoch 4/5
2025-08-22 00:06:22 - INFO - avg Loss: 0.6077947603841113
2025-08-22 00:06:22 - INFO - Evaluation start
2025-08-22 00:07:22 - INFO - Mispredictions (up to 5 examples):
2025-08-22 00:07:22 - INFO - Predicted: 19.0, Actual: 18.0
2025-08-22 00:07:22 - INFO - Predicted: 18.0, Actual: 3.0
2025-08-22 00:07:22 - INFO - Predicted: 21000.0, Actual: 70000.0
2025-08-22 00:07:22 - INFO - Predicted: 1700.0, Actual: 540.0
2025-08-22 00:07:22 - INFO - Predicted: 14.0, Actual: 20.0
2025-08-22 00:07:22 - INFO - Epoch                                   4         
2025-08-22 00:07:22 - INFO - Train Loss                              0.6078
2025-08-22 00:07:22 - INFO - Test Loss                               0.6339
2025-08-22 00:07:22 - INFO - Whole Num Acc                           3.184230%
2025-08-22 00:07:22 - INFO - Digit-wise Acc                          41.663717%
2025-08-22 00:07:22 - INFO - MSE                                     8078444027.148598
2025-08-22 00:07:22 - INFO - R^2                                     0.041457473844752
2025-08-22 00:07:22 - INFO - Learning Rate                           0.000007
2025-08-22 00:07:22 - INFO - ----------------------------------------------------------------------------------------------------
2025-08-22 00:07:22 - INFO - Starting Epoch 5/5
2025-08-22 00:23:23 - INFO - avg Loss: 0.5861658650076288
2025-08-22 00:23:23 - INFO - Evaluation start
2025-08-22 00:24:23 - INFO - Mispredictions (up to 5 examples):
2025-08-22 00:24:23 - INFO - Predicted: 16.0, Actual: 18.0
2025-08-22 00:24:23 - INFO - Predicted: 16.0, Actual: 3.0
2025-08-22 00:24:23 - INFO - Predicted: 21000.0, Actual: 70000.0
2025-08-22 00:24:23 - INFO - Predicted: 1500.0, Actual: 540.0
2025-08-22 00:24:23 - INFO - Predicted: 14.0, Actual: 20.0
2025-08-22 00:24:23 - INFO - Epoch                                   5         
2025-08-22 00:24:23 - INFO - Train Loss                              0.5862
2025-08-22 00:24:23 - INFO - Test Loss                               0.6304
2025-08-22 00:24:23 - INFO - Whole Num Acc                           2.880970%
2025-08-22 00:24:23 - INFO - Digit-wise Acc                          41.769912%
2025-08-22 00:24:23 - INFO - MSE                                     8127240523.448825
2025-08-22 00:24:23 - INFO - R^2                                     0.035667557287311
2025-08-22 00:24:23 - INFO - Learning Rate                           0.000000
2025-08-22 00:24:23 - INFO - Starting Final evaluation.
2025-08-22 00:24:23 - INFO - Evaluation start
2025-08-22 00:25:24 - INFO - Mispredictions (up to 5 examples):
2025-08-22 00:25:24 - INFO - Predicted: 16.0, Actual: 18.0
2025-08-22 00:25:24 - INFO - Predicted: 16.0, Actual: 3.0
2025-08-22 00:25:24 - INFO - Predicted: 21000.0, Actual: 70000.0
2025-08-22 00:25:24 - INFO - Predicted: 1500.0, Actual: 540.0
2025-08-22 00:25:24 - INFO - Predicted: 14.0, Actual: 20.0
2025-08-22 00:25:24 - INFO - Final Test Results:
2025-08-22 00:25:24 - INFO - Test Loss                               0.6304
2025-08-22 00:25:24 - INFO - Whole Num Accuracy                      2.880970%
2025-08-22 00:25:24 - INFO - Digit-wise Accuracy                     41.769912%
2025-08-22 00:25:24 - INFO - MSE                                     8127240523.448825
2025-08-22 00:25:24 - INFO - R^2                                     0.035667557287311
